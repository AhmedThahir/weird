# Univariate methods

In this chapter, we will explore various methods for identifying and displaying anomalies when there is only one variable.  Throughout the chapter, we will use two illustrative examples.

1. The cricket batting averages discussed in Section \@ref(sec:scatterplots). Recall that this appeared to contain one genuine anomaly, the batsman Don Bradman.
2. Old Faithful eruption durations since 2015, also discussed in Section \@ref(sec:scatterplots). For these data, there were two extreme anomalies --- one at nearly 2 hours and one at 1 second --- and several "inliers" in a area of low density between 140 and 180 seconds.
3. One thousand draws from a N(0,1) distribution. Of course, this contains no genuine anomalies, as all the data come from the same underlying probability distribution. This example is used to check how many false anomalies are identified by different anomaly detection methods.
4. Nineteen draws from a N(0,1) distribution, along with the value 4. The latter is an anomaly as it is unlikely to arise from the N(0,1) distribution.

The two artificial examples are designed to test different methods when there are large and small data sets.

First, we will generate the data for the last two examples. A seed is set to allow readers to replicate these examples, even though they are using randomly generated numbers.

```{r n01a, fig.asp=0.2, fig.cap="One thousand observations from a N(0,1) distribution."}
set.seed(1)
n01a <- tibble(y = rnorm(1000))
n01a %>%
  ggplot(aes(x = y, y = 1)) +
  geom_jitter(width = 0, alpha = 0.5) +
  scale_y_discrete() +
  labs(y = "", x = "N(0,1)")
```

```{r n01b, fig.asp=0.2, fig.cap="Nineteen observations from a N(0,1) distribution along with one anomaly."}
n01b <- tibble(y = c(rnorm(19), 4))
n01b %>%
  ggplot(aes(x = y, y = 1)) +
  geom_jitter(width = 0, alpha = 0.5) +
  scale_y_discrete() +
  labs(y = "", x = "N(0,1)")
```

## Z scores and related tests

Let's start with some bad ideas that are still sometimes used. Probably the most widely used is the idea of $z$-scores which assume the data come from a normal distribution. If our data are given by $y_1,\dots,y_n$, then their $z$ scores are given by
$$z_i = (y_i - \bar{y})/s_y$$
where $\bar{y}$ is the mean and $s_y$ is the standard deviation of the observations.

Some books recommend that observations where the absolute value of $z$ is above some threshold (usually 3) be identified as anomalies. This is a bad idea for several reasons.

1. If the data really do come from a normal distribution that has been contaminated with anomalies, then the estimated mean ($\bar{y}$) and standard deviation $s_y$ will also be affected by those anomalies. Any anomaly detection method should be relatively robust to the anomalies in the data.
2. Having a fixed threshold regardless of sample size means that the probability of a spurious anomaly increases with the sample size.
3. The assumption of normality is very unlikely to be satisfied with most real data.

Let's see what happens when we apply this test to the four examples.

```{r zscore1}
cricket_batting %>%
  filter(Innings > 20) %>%
  mutate(z = (Average - mean(Average)) / sd(Average)) %>%
  filter(abs(z) > 3) %>%
  select(Player, Average, z)
oldfaithful %>%
  mutate(z = (duration - mean(duration)) / sd(duration)) %>%
  filter(abs(z) > 3)
n01a %>%
  mutate(z = (y - mean(y)) / sd(y)) %>%
  filter(abs(z) > 3)
n01b %>%
  mutate(z = (y - mean(y)) / sd(y)) %>%
  filter(abs(z) > 3)
```

 1. Don Bradman is correctly identified as the only outlier in the cricket batting averages.
 2. Only the extreme 2-hour duration is identified. We already know there was an additional strange 1-second eruption, plus several unusual eruptions between 140 and 180 seconds in length.
 3. One spurious anomaly is identified in the 1000 N(0,1) observations.
 4. The anomaly added to the 19 N(0,1) observations has not been identified.

If we replace the mean and standard deviation by more robust estimates (the median and IQR/1.34), we obtain the same results in the first and third examples, and we spot the true anomaly in the fourth example. But the second Old Faithful example gives even worse results.

```{r check, include=FALSE}
# Check last statement
n1 <- cricket_batting %>%
  filter(Innings > 20) %>%
  mutate(z = (Average - median(Average)) / IQR(Average) * 1.34) %>%
  filter(abs(z) > 3) %>%
  select(Player, Average, z) %>%
  NROW()
n2 <- oldfaithful %>%
  mutate(z = (duration - median(duration)) / IQR(duration) * 1.34) %>%
  filter(abs(z) > 3) %>%
  NROW()
n3 <- n01a %>%
  mutate(z = (y - median(y)) / IQR(y) * 1.34) %>%
  filter(abs(z) > 3) %>%
  NROW()
n4 <- n01b %>%
  mutate(z = (y - median(y)) / IQR(y) * 1.34) %>%
  filter(abs(z) > 3) %>%
  NROW()
stopifnot(n1 == 1L)
stopifnot(n2 == 209L)
stopifnot(n3 == 1L)
stopifnot(n4 == 1L)
of_threshold <- oldfaithful %>%
  mutate(z = (duration - median(duration)) / IQR(duration) * 1.34) %>%
  filter(abs(z) <= 3) %>%
  pull(duration) %>%
  min()
```

```{r zscore2}
oldfaithful %>%
  mutate(z = (duration - median(duration)) / (IQR(duration) / 1.34)) %>%
  filter(abs(z) > 3)
```

Now there are `r n2` out of `r NROW(oldfaithful)` observations identified as anomalous, including all of those below `r of_threshold` seconds.

In any case, even if the data did come from a normal distribution, the probability of an observation being more than 3 standard deviations from the mean is `r round(2*pnorm(-3),4)`, so we would expect to see 1 in every `r round(.5/pnorm(-3))` regular observations being identified as an anomaly using this approach.

### Peirce's criterion {-}

Benjamin Peirce was a Harvard mathematician in the mid 1800s who worked with astronomical data which were prone to anomalous observations. In @Peirce1852 he proposed the first known test based on what are now called $z$-scores. His criteria was that any observations with $|z| > c$ should be "rejected", where $c$ is a complicated function depending on the sample size $n$ and the number of suspected anomalies. Figure \@ref(fig:zscorecriteria) shows the value of $c$ as a function of sample size, when there is only one suspected anomaly.

```{r zscorecriteria, echo=FALSE, fig.cap="Criteria for anomalies based on z-scores."}
n <- exp(seq(log(3), log(1e5), l = 100))
threshold <- numeric(length(n))
for (i in seq_along(n)) {
  threshold[i] <- weird:::peirce_threshold(n[i])
}
tibble(n = n, c = threshold) %>%
  ggplot(aes(x = n, y = c)) +
  geom_line() +
  geom_line(aes(y = qnorm(1 - 0.25 / n)), col = "red") +
  scale_x_log10() +
  labs(x = "n (sample size)", y = "c (threshold)") +
  geom_label(aes(x = 1500, y = 4.1, label = "Peirce criterion")) +
  geom_label(aes(x = 1e4, y = 3.55, label = "Chauvenet criterion"), col = "red")
```

The threshold increases with sample size $n$ to allow for the increasing likelihood of observations from the extreme tails of the distribution.

The `peirce_anomalies()` function returns a logical vector indicating which observations are anomalous under this criterion. Let's apply it to the four examples.

```{r peirce_examples}
cricket_batting %>% filter(peirce_anomalies(Average))
oldfaithful %>% filter(peirce_anomalies(duration))
n01a %>% filter(peirce_anomalies(y))
n01b %>% filter(peirce_anomalies(y))
```

1. When applied to the test cricket batting averages, it doesn't even find the obvious anomaly of Don Bradman.
2. When applied to the Old Faithful eruption durations, it finds only the most extreme duration.
3. Again, one spurious anomaly is identified in the 1000 N(0,1) observations.
4. The true anomaly has been spotted amongst the 19 N(0,1) observations.

This failure is at least partly due to the standard deviation being highly inflated by the existence of the anomalies in the data set.

### Chauvenet's criterion {-}

Peirce's proposal was largely superseded by an alternative proposed by the astrophysicist William Cauvenet, which was much simpler to describe. He suggested [@Chauvenet1863] replacing the threshold $c$ by the $1-0.25/n$ quantile from the standard normal distribution. This threshold is also shown in Figure \@ref(fig:zscorecriteria). A consequence of this choice is that Chauvenet's criterion will reject, on average, half an observation of genuine data from a normal distribution regardless of the value of $n$. However, for non-Gaussian data, there is no such guarantee that genuine observations will not be detected as anomalies. Despite its flaws, the method is still widely used in some disciplines, especially engineering.

The `chauvenet_anomalies()` function can be used to implement this test. For our four examples, it gives identical results to those above for `peirce_anomalies()`.

```{r checkchauvenet, include=FALSE}
n1 <- cricket_batting %>%
  filter(chauvenet_anomalies(Average)) %>%
  NROW()
n2 <- oldfaithful %>%
  filter(chauvenet_anomalies(duration)) %>%
  NROW()
n3 <- n01a %>%
  filter(chauvenet_anomalies(y)) %>%
  NROW()
n4 <- n01b %>%
  filter(chauvenet_anomalies(y)) %>%
  NROW()
stopifnot(n1 == 0L)
stopifnot(n2 == 1L)
stopifnot(n3 == 1L)
stopifnot(n4 == 1L)
```

### Maximum z-score test {-}

By the 20th century, the concept of hypothesis testing had been developed, and the $t$-distribution had been discovered, and both were applied to the identification of anomalies using $z$-scores. Many tests were developed under different assumptions about the underlying distribution and what was assumed to be known [@Hawkins1980]. We will mention just two of them here, as they are the most widely used.

Egon Pearson and Chandra Sekar proposed [@Pearson1936] that an observation be considered an anomaly if $|z_i|> c_\alpha$, where the critical value is given by
$$
c_\alpha = t_{\alpha/n, n-2} \sqrt{\frac{n-1}{n-2+t^2_{\alpha/n, n-2}}}
$$
and $t_{p, m}$ is the $1-p$ quantile of the $t$ distribution with $m$ degrees of freedom. Later, this was extended by Frank Grubbs [@Grubbs1950] who proposed  using
$$
c_\alpha = \frac{(n-1)t_{\alpha/2n, n-2}}{\sqrt{n(n-2 + t^2_{\alpha/2n, n-2})}}.
$$

Figure \@ref(fig:zscoretests) shows the critical values at $\alpha=0.05$ for these tests, along with the corresponding value from @Chauvenet1863 for comparison.

(ref:zscoretests) Critical values for maximum $z$-score tests with $\alpha=0.05$.

```{r zscoretests, echo=FALSE, fig.cap="(ref:zscoretests)"}
alpha <- 0.05
n <- exp(seq(log(3), log(1e5), l = 100))
t1 <- qt(1 - alpha / n, n - 2)
t2 <- qt(1 - alpha / (2 * n), n - 2)
tibble(n = n) %>%
  ggplot(aes(x = n)) +
  geom_line(aes(y = t1 * sqrt((n - 1) / (n - 2 + t1^2))), col = "black") +
  geom_line(aes(y = (n - 1) / sqrt(n) * sqrt(t2^2 / (n - 2 + t2^2))), col = "blue") +
  geom_line(aes(y = qnorm(1 - 0.25 / n)), col = "red") +
  scale_x_log10(
    limits = c(3, 2e6),
    breaks = 10^(1:6),
    minor_breaks = NULL,
    labels = format(10^(1:6), scientific = FALSE, trim = TRUE)
  ) +
  labs(x = "n (sample size)", y = latex2exp::TeX("$c_{\\alpha}$ (threshold)")) +
  geom_label(aes(x = 1.1e5, y = 4.8, label = "Pearson-Sekar test", hjust = "left"), col = "black") +
  geom_label(aes(x = 1.1e5, y = 5.1, label = "Grubbs test", hjust = "left"), col = "blue") +
  geom_label(aes(x = 1.1e5, y = 4.5, label = "Chauvenet criterion", hjust = "left"), col = "red")
```

This shows that for small sample sizes ($n<10$), the critical value for Grubbs' test is too low and is likely to lead to many spurious anomalies being detected.

We can apply the test using the `grubbs.test()` function from the `outliers` package.

```{r}
library(outliers)
cricket_batting %>%
  filter(Innings > 20) %>%
  pull(Average) %>%
  grubbs.test()
grubbs.test(oldfaithful$duration)
grubbs.test(n01a$y)
grubbs.test(n01b$y)
```

An outlier is identified in each case. 

These tests are sometimes applied iteratively, where observations are removed from the data if determined to be anomalies, and the test re-applied to the remaining data. This process continues until no more anomalies are found. However, this procedure will clearly change the size of the test due to the problem of multiple comparisons. 

I do not recommend any tests based on $z$-scores because they are not robust to the anomalies they are trying to detect, and are based on overly-restrictive assumptions about the underlying distribution.

## Other statistical tests

### Dixon's Q test {-}

If $y_{(1)},\dots,y_{(n)}$ denote the ordered values of our sample, then Dixon's Q statistic [@Dixon1950] is given by
$$
  Q = \frac{y_{(n)} - y_{(n-1)}}{y_{(n)} - y_{(1)}},
$$
the ratio of the difference between the two largest values to the range of the data. A variant of the statistic uses $y_{(2)}-y_{(1)}$ in the denominator instead, the difference between the second smallest and minimum observations. For samples sizes $n$ in the range 3 to 30, we can use the `dixon.test()` function from the `outliers` package to perform the test. For larger sample sizes, critical values are not available for this test. So we can only use it on the last of our four examples, where it finds the outlying observation.

```{r}
dixon.test(n01b$y)
```

The test has an obvious flaw in that the minimum $y_{(1)}$ is also potentially an anomaly, and then the assumptions of the test break down.


## Boxplots

Boxplots were invented by John Tukey as a quick summary of medium sized data sets. They are widely used to identify anomalies, which are shown as separate points in the plot.

Figure \@ref(fig:cricketbox) shows a boxplot of the cricket batting average data, previously shown in  \@ref(fig:cricket1).

```{r cricketbox, fig.asp=0.2, fig.cap="(ref:cricket1)"}
cricket_batting %>%
  filter(Innings > 20) %>%
  ggplot(aes(x = Average, y = 1)) +
  geom_boxplot() +
  scale_y_discrete() +
  labs(y = "", x = "Career batting average")
```

The middle line in the box shows the median, and the ends of the box are the fourths ($L_F$ and $U_F$). Half of all observations lie within the box. The width of the box is called the "interquartile range", defined by $IQR = U_F - L_F$. Any points more than $1.5*IQR$ outside the box are shown as anomalies and appear as separate points in the plot. The "whiskers" that extend out each side of the box show the range of the remaining points.

Originally, Tukey proposed two levels of outliers --- those more than $1.5*IQR$ beyond the box were labelled "outside" values, while those more than $3*IQR$ beyond the box were labelled "far out" values. Most software implementations of boxplots do not distinguish between these groups.

In this cricket batting example, the boxplot works well because the data set is not too large or small, and the distribution of points other than the anomaly is unimodal.

However, boxplots can be misleading, and are they are limited in at least two respects.

1. For large data sets, boxplots show too many points as anomalies, and it is hard to distinguish them.
2. Boxplots assume that the distribution of the data is unimodal.

```{r standardnormal, echo=FALSE}
q1 <- qnorm(0.25)
q3 <- qnorm(0.75)
iqr <- q3 - q1
whisker1 <- q1 - 1.5 * iqr
whisker2 <- q3 + 1.5 * iqr
```

To better understand the first problem, imagine the data comprised $n$ observations from a standard normal distribution N(0,1). Figure \@ref(fig:normalboxplot) shows an example with 10000 points.

```{r normalboxplot, fig.asp=0.2, fig.cap="Boxplot of 10000 draws from a standard normal distribution."}
tibble(x = rnorm(10000)) %>%
  ggplot(aes(x = x, y = 1)) +
  geom_boxplot() +
  scale_y_discrete() +
  labs(y = "")
```

Many anomalies are shown, but since all observations come from a simple distribution, none of them are actually anomalies. For this distribution, Q1 $= `r round(q1,2)`$, Q3 $= `r round(q3,2)`$, IQR $= `r round(iqr,2)`$, and so any observations less than $`r round(q1,2)` - 1.5\times `r round(iqr,2)` = `r round(whisker1, 2)`$ or greater than $`r round(q3,2)` + 1.5\times `r round(iqr,2)` = `r round(whisker2, 2)`$ would be identified as "anomalous" by a boxplot and plotted as separate points. The probability of a standard normal observation being at least $`r round(whisker2, 2)`$ in absolute value is $`r sprintf("%.5f", 1-pnorm(whisker2))`$. So with 10000 observations, we would have $`r round(10000*(1-pnorm(whisker2)))`$ anomalies identified, none of which would be a genuine anomaly.

The second problem is demonstrated using the Old Faithful eruption duration data, shown in Figure \@ref(fig:oldfaithful1). As before, we will omit the largest value so we can see the details in the remaining data.

```{r oldfaithful2a, fig.asp=0.2, fig.cap="Boxplot of Old Faithful eruption durations since 2015, omitting the one eruption that lasted nearly two hours."}
oldfaithful %>%
  filter(duration < 6000) %>%
  ggplot(aes(x = duration, y = 1)) +
  geom_boxplot() +
  labs(y = "", x = "Duration (seconds)") +
  scale_y_discrete()
```

Quite a few anomalies are shown, including the one-second eruption we identified earlier. But the remaining "anomalies" are not particularly unusual observations. All the points below 180 seconds are identified as anomalies, even though we know that observations in the region between 100 and 140 are not unusual for this geyser. Because the boxplot does not allow for more than one mode, all the points in the second smaller cluster are identified as anomalies. The points around 300 seconds are also not really anomalies --- these are just values in the upper tail of the distribution for eruptions.

## Modified IQR method

```{r modifiediqr, echo=FALSE}
q1 <- qnorm(0.25)
q3 <- qnorm(0.75)
iqr <- q3 - q1
tukey1 <- 2 * (1 - pnorm(q3 + 1.5 * iqr))
tukey2 <- 2 * (1 - pnorm(q3 + 3 * iqr))
```


Under Tukey's boxplot approach to identifying outliers, a regular outlier is more than 1.5IQR beyond the quartiles, while an extreme outlier is more than 3IQR beyond the quartiles. For a normal distribution, the probability of genuine observations lying beyond these thresholds is `r sprintf("%.4f",tukey1)` and `r sprintf("%.7f",tukey2)` respectively, so for very large sample sizes, many spurious anomalies will be identified. Even with 1000 observations, Tukey's approach will find spurious anomalies in a normal distribution with probability `r 1 - (1-tukey1)^1000`.

@Barbato2011 proposed a modification to the boxplot approach to identifying outliers, where the IQR in these thresholds is replaced with IQR$[1+0.1\log(n/10)]$. This allows the limits to increase with the sample size, in a way that controls the probability of false anomalies. Figure \@ref(fig:probanomaly) shows the probability of a regular or extreme anomaly using Tukey's boxplot approach compared to those obtained using the modified IQR approach of @Barbato2011.

```{r probanomaly, echo=FALSE, fig.cap="Probability of anomaly based on the boxplot approach of Tukey, and the modified IQR approach of Barbato et al."}
tibble(n = exp(seq(log(3), log(1e6), l = 100))) %>%
  mutate(
    Tukey1 = 2 * (1 - pnorm(q3 + 1.5 * iqr)),
    Tukey2 = 2 * (1 - pnorm(q3 + 3 * iqr)),
    Barbato1 = 2 * (1 - pnorm(q3 + 1.5 * iqr * (1 + 0.1 * log(n / 10)))),
    Barbato2 = 2 * (1 - pnorm(q3 + 3 * iqr * (1 + 0.1 * log(n / 10))))
  ) %>%
  pivot_longer(Tukey1:Barbato2, names_to = "method", values_to = "probability") %>%
  mutate(
    level = stringr::str_extract(method, "\\d"),
    level = if_else(level == "1", "Regular outlier", "Extreme outlier"),
    method = stringr::str_extract(method, "[A-Za-z]*"),
    level = factor(level, levels = c("Regular outlier", "Extreme outlier")),
    method = factor(method, levels = c("Tukey", "Barbato")),
    probability = 1 - (1 - probability)^n
  ) %>%
  ggplot(aes(x = n, y = probability)) +
  geom_line() +
  facet_grid(level ~ method) +
  labs(y = "Probability of an anomaly in a normal distribution", x = "Sample size") +
  scale_x_log10(
    limits = c(3, 2e6),
    breaks = 10^(1:6),
    minor_breaks = NULL,
    labels = format(10^(1:6), scientific = FALSE, trim = TRUE)
  )
```

Even with a huge sample size, the probability of spotting a genuine anomaly using this modified approach is less than 1/2.

Let's apply this approach to our four examples. First we will write a short function to implement the idea.

```{r barbato4}
barbato_anomaly <- function(y, extreme = FALSE) {
  n <- length(y)
  q1 <- quantile(y, 0.25, na.rm = TRUE)
  q3 <- quantile(y, 0.75, na.rm = TRUE)
  threshold <- (1.5 + 1.5 * extreme) * (q3 - q1) * (1 + log(n / 10))
  return(y > q3 + threshold | y < q1 - threshold)
}
cricket_batting %>%
  filter(Innings > 20) %>%
  filter(barbato_anomaly(Average))
oldfaithful %>% filter(barbato_anomaly(duration))
n01a %>% filter(barbato_anomaly(y))
n01b %>% filter(barbato_anomaly(y))
```

Only the extreme outlier in the duration data is identified as an anomaly. 

## Letter value plots

The problem that boxplots have with large data sets was addressed by @Hofmann2017-hz who introduced "letter-value" plots, a variation of boxplots that replace the whiskers with a variable number of letter values. In these plots, each pair of letter values marks the boundaries of a box. The box bounded by the fourths is the same as the box of a boxplot; the additional boxes extend to successive letter values until the quantiles corresponding to the letter values can no longer be estimated sufficiently accurately from the available data.

These can be produced using the `lvplot` package.

```{r cricketboxlv, fig.asp=0.2, fig.cap="Letter value plot of career batting averages for all men and women who played test cricket and batter more than 20 times."}
library(lvplot)
cricket_batting %>%
  filter(Innings > 20) %>%
  ggplot(aes(x = 1, y = Average)) +
  geom_lv(aes(fill = ..LV..)) +
  scale_x_discrete() +
  coord_flip() +
  labs(x = "", y = "Career batting average") +
  theme(legend.key.height = unit(.2, "cm"))
```

```{r lv, echo=FALSE}
lv <- cricket_batting %>%
  filter(Innings > 20) %>%
  stat_lv(mapping = aes(y = Average))
```

Here the median is given by M, the fourths by F, and so on. So the middle box (F) is bounded by the fourths and contains all but 2/4 the data; the next box (E) is bounded by the eighths and contains all but 2/8 of the data; then D is bounded by the sixteenths and contains all but 2/16 of the data; and so on.

In this example, the most extreme box (labelled Z) is bounded by the points that fall within the 1/256 letter values. So it contains all but 2/256 of the data, and shows $2 / 256 \times `r NROW(filter(cricket_batting, Innings > 20))` = `r round(2/256*NROW(filter(cricket_batting, Innings > 20)))`$ points as anomalies.

The stopping rule used in the letter value plot is to show the boxes up to letter value $k$, where
$$
  0.5\sqrt{2d_k} z_{1-\alpha/2} > d_{k+1}
$$
and $z_{1-\alpha/2}$ is the $1-\alpha/2$ quantile of a standard Gaussian distribution. This choice is based on the idea that the edges of the boxes are quantile estimates, and the confidence interval for each  quantile estimate that is displayed should not overlap the subsequent quantile estimate. The Gaussian distribution arises because the quantile estimate has an approximate Gaussian distribution due to the Central Limit Theorem. This stopping rule means that, on average, there should be fewer than $2z^2_{1-\alpha/2}$ legitimate observations in the tails. By default, $\alpha=0.05$, so that, on average, there should be fewer than $2 \times (`r qnorm(1-0.05/2)`)^2 = `r round(2* qnorm(1-0.05/2)^2,1)`$ legitimate observations in the tails, regardless of the size of the data set.

Letter value plots were not designed to detect anomalies, but to be a useful data visualization tool for univariate distributions with large numbers of observations. So the display of legitimate observations in the tails of the distribution is by design, not a flaw.

In this cricketing example, it looks like there is one true anomaly (Don Bradman) and the remaining 8 observations displayed directly are simply in the tails of the distribution of the remaining data.

When applied to the remaining examples, we see approximately 10--20 observations shown as individual points in each case. The code to produce these is very similar to that shown for Figure \@ref(fig:cricketboxlv), so is not reproduced here.

```{r lvplots1, echo=FALSE, fig.asp=0.2, fig.cap="Letter value plot of Old Faithful eruption durations, omitting the very long 2 hour duration."}
oldfaithful %>%
  filter(duration < 7000) %>%
  ggplot(aes(x = 1, y = duration)) +
  geom_lv(aes(fill = ..LV..)) +
  scale_x_discrete() +
  coord_flip() +
  labs(x = "", y = "Eruption durations (seconds)") +
  theme(legend.key.height = unit(.2, "cm"))
```

```{r lvplots2, echo=FALSE, fig.asp=0.2, fig.cap="Letter value plot of 1000 N(0,1) observations."}
n01a %>%
  ggplot(aes(x = 1, y = y)) +
  geom_lv(aes(fill = ..LV..)) +
  scale_x_discrete() +
  coord_flip() +
  labs(x = "") +
  theme(legend.key.height = unit(.2, "cm"))
```

```{r lvplots3, echo=FALSE, fig.asp=0.2, fig.cap="Letter value plot of 19 N(0,1) observations with an anomaly at 4."}
n01b %>%
  ggplot(aes(x = 1, y = y)) +
  geom_lv(aes(fill = ..LV..)) +
  scale_x_discrete() +
  coord_flip() +
  labs(x = "")
```

In this last example, because there are only 20 observations, there is not enough data to estimate the quantiles beyond the fourths. So only the middle box is shown.

## HDR boxplots

> Need gghdr package to be updated.

## Lookout algorithm

A popular way of defining anomalies is that they are observations of low probability. The kernel density estimate at each observation is (equation \@ref(eq:kde))
$$
  f_i = \hat{f}(y_i) = \frac{1}{n} \sum_{j=1}^n K_h(y_i-y_j),  
$$
and we define the "**kde score**" at each observation as $s_i = -\log(f_i)$. These provide a measure of how anomalous each point is, and are defined for all observations provided the kernel is non-negative everywhere (which it is for a Gaussian kernel). Anomalies are points where the kde scores are relatively large. 

We also define the "leave-one-out" kernel density estimate --- the estimate of $f(y_i)$ obtained using all data other than $y_i$. Note that the contribution of the $i$th point to the kernel density estimate at that point is $K_h(0)/n$, so the leave-one-out kernel density estimate is simply $f_{-i} = f_i - K(0)/(nh)$.

An observation point far from all other observations will have $f_i \approx K_h(0)/n$ because $K_h(y_i-y_j)\approx 0$ when $|y_i-y_j|$ is large. So $f_{-i}\approx 0$ for these observations, while the largest possible kde score is
$$
  -\log(K_h(0)/n) \approx \log(nh\sqrt{2\pi}) 
$$
for a Gaussian kernel.

For the Old Faithful eruption duration data, we obtain the following kde scores.

```{r, fig.asp = 0.2, fig.cap="KDE scores for the Old Faithful eruption durations."}
oldfaithful %>%
  mutate(score = kde_scores(duration)) %>%
  ggplot(aes(x = score, y = 1)) +
  geom_jitter(width = 0) +
  scale_y_discrete() +
  labs(y = "", x = "KDE score")
```

The two large scores correspond to the extreme 2 hour duration, and the tiny 1 second duration. In both cases, the kde score is at its maximum.

The "lookout" algorithm (standing for Leave-One-Out Kernel density estimates for OUTlier detection) was proposed by @lookout2021 and uses these kde scores to find the probability of each observation being an anomaly.

In this procedure, we fit a Generalized Pareto Distribution to $-\log(f_i)$ using the POT approach discussed in Section \@ref(sec:evt), with the $90^{\text{th}}$ percentile as the threshold.

```{r ofpot}
of_scores <- oldfaithful %>%
  mutate(
    score = kde_scores(duration),
    looscore = kde_scores(duration, loo = TRUE),
  )
threshold <- quantile(of_scores$score, prob = 0.90)
gpd <- evd::fpot(oldfaithful$duration, threshold = threshold)$estimate
```

Now we apply the fitted distribution to the leave-one-out scores to obtain the probabilities that each observation is an outlier.

```{r ofpot2}
of_scores %>%
  mutate(
    pval = evd::pgpd(looscore,
      loc = threshold,
      scale = gpd["scale"], shape = gpd["shape"], lower.tail = FALSE
    )
  ) %>%
  arrange(pval)
```

Low probabilities indicate likely outliers and high probabilities indicate normal points.

This procedure has identified only the minimum and maximum eruptions as likely outliers, with all other values having very high probability of being regular observations.

The above code was introduced to illustrate each step of the procedure, but it is simpler to use the `lookout` package. This package uses the Epanechnikov kernel rather than the Gaussian kernel, but otherwise the procedure is equivalent to what is described above. We shall apply it to the four examples used throughout this chapter.

```{r lookout}
cricket_batting %>%
  filter(Innings > 20) %>%
  pull(Average) %>%
  lookout::lookout()
lookout::lookout(oldfaithful$duration)
lookout::lookout(n01a$y)
lookout::lookout(n01b$y)
```
