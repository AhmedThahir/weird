# Introduction {#ch:intro}

Data analysis is about finding the stories hidden in the mass of information that make up a data set. Usually we are interested in understanding the major patterns --- the relationships that describe how most of the data behave. But sometimes we need to look at the weird observations --- the data that doesn't follow the crowd and behaves differently. We call these weird observations "anomalies". They are the mavericks in the data, and in this book they are what we find interesting.

Anomalies are often a nuisance. For example, they may be simply recording errors that are contaminating our data. We want to find them, remove them, and get on with analysing the bulk of the data. At other times, anomalies are the observations we care about. They tell us things that might otherwise go unnoticed if we only consider how the majority of observations behave.

### Definitions {-}

An anomaly is an observation that behaves differently from the bulk of the data. They are also called "outliers", "novelties", "deviants", "abnormalities" or "discordants". We prefer to use "anomalies" as it is more general than outliers (some anomalies are actually inliers as we shall see) and it is more widely used than the other options.

An old definition due to @Barnett1978 states

> an outlier in a set of data [is] an observation (or subset of observations) which appears to be inconsistent with the remainder of that set of data.

@Hawkins1980 defined it like this

> An outlier is an observation which deviates so much from the other observations as to arouse suspicions that it was generated by a different mechanism.

A more mathematical definition is that anomalies are observations that come from a different probability distribution than the majority of observations. However, that does not help much as it is always possible to define a mixture probability distribution that includes several component distributions. There are also some probability distributions with "heavy tails", so genuine observations can occur a long way from the bulk of the data.

So rather than trying to define anomalies more precisely, we shall deliberately proceed with the fuzzy and subjective approach where anomalies are suspiciously different or inconsistent with the rest of the data.

### Rejecting anomalies {-}

Many analysts have thrown away apparent anomalies because they were assumed to be errors. There are even formal statistical tests to tell you which observations should be ignored. In my view, this is a dangerous practice. No anomalies should be removed unless you understand what led to their unusual behaviour in the first place.

> Add story of ozone layer

## Strip plots and scatterplots {#sec:scatterplots}

When there are no more than a few thousand observations, it is useful to start with simple plots that allow you to look at the observations directly with no processing or modelling to hide what is going on.

Let's start with some examples using only one or two variables. These examples will be revisited in the next couple of chapters as we introduce new anomaly detection tools and graphics.

### Example: Test cricket batting averages {-}

```{r cricket0, echo=FALSE}
batting <- cricket_batting %>%
  filter(Innings > 20)
donave <- max(batting$Average)
```

Don Bradman was an Australian cricketer in the first half of the 20th century, and is renowned as the best batsman to ever play the game. The most common measure of a batter's ability is their career average --- the total number of runs made divided by the number of times they were dismissed. Figure \@ref(fig:cricket1) shows a strip plot of the career averages for all `r NROW(batting)` men and women to have played test cricket and batted more than 20 times.

(ref:cricket1) Career batting averages for all men and women to have played test cricket and batted more than 20 times. The anomaly is Don Bradman, who averaged `r round(donave, 2)` over his career.

```{r cricket1, fig.asp=0.2, fig.cap="(ref:cricket1)"}
cricket_batting %>%
  filter(Innings > 20) %>%
  ggplot(aes(x=Average, y=1)) +
  geom_jitter(width=0, alpha=0.5) +
  scale_y_discrete() +
  labs(y="", x="Career batting average")
```

The points are "jittered" vertically to reduce overplotting, and made slightly transparent to show where overplotting occurs. There is an obvious anomaly on the right of the plot; this point is Don Bradman who averaged `r round(donave,2)` over his career.  Clearly, Don Bradman was much better than any of the other men and women who have played cricket.

### Example: Old Faithful Geyser eruptions {-}

Some anomalies are not so obvious, and occur within the range of the rest of the data.

A good example of this is the duration of eruptions of the Old Faithful Geyser in Yellowstone National Park, Wyoming, USA. Data on this geyser have been collected for about 150 years, and it was named "Old Faithful" due to the relatively predictable timing and length of its eruptions. Figure \@ref(fig:oldfaithful1) shows the duration of all eruptions recorded since 2015.

```{r oldfaithful1, fig.asp=0.2, fig.cap="Old Faithful eruption durations since 2015. The large anomaly is an eruption on 7&nbsp;December 2015 which lasted nearly two hours."}
oldfaithful %>%
  ggplot(aes(x=duration, y=1)) +
  geom_jitter(width=0, alpha=0.5) +
  labs(y="", x="Duration (seconds)") +
  scale_y_discrete()
```

The big anomaly on the right was an eruption that lasted nearly two hours on 7 December 2015. This makes it difficult to see any detail in the rest of the data, so let's omit it so we can look at the remaining data more clearly.

```{r oldfaithful2, fig.asp=0.2, fig.cap="Old Faithful eruption durations since 2015, omitting the one eruption that lasted nearly two hours."}
oldfaithful %>%
  filter(duration < 7000) %>%
  ggplot(aes(x=duration, y=1)) +
  geom_jitter(width=0, alpha=0.5) +
  labs(y="", x="Duration (seconds)") +
  scale_y_discrete()
```

We see that almost all the remaining eruptions were between 100 and 300 seconds in length, with one extremely short anomalous duration (of 1 second). However, the plot reveals another feature of the data. The majority of observations are between 200 and 300 seconds, with a smaller group at around 120 seconds. Very few observations fall between 140 and 180 seconds. Those that do can be considered "inliers" --- anomalous points that lie within the range of the rest of the data but in regions of low density.

The two clusters of observations characterise two eruption modes for the Old Faithful geyser: short durations (around 2 minutes in length) and long durations (between 3 and 5 minutes in length). There was a local earthquake in 1998 which changed the distribution of durations. Before 1998, the durations were more evenly split between the two clusters, but currently the long durations are much more common.

### Example: wine prices and quality {-}

Once we have more than one variable in our data set, anomalies can occur due to the combination of variables which may not appear anomalous in any one of the variables. For example, suppose we observed height and age for a large number of people. A height of 180 cm would not be identified as anomalous in the distribution of height, and an age of 4 years would not be identified as anomalous in the distribution of age. However, a 180cm 4-year-old would be an anomaly due to the unusual combination of height and age.

Figure \@ref(fig:shiraz) shows a scatterplot of data on `r wine_reviews %>% filter(variety %in% c("Shiraz", "Syrah")) %>% NROW()` Syrah wines (also known as Shiraz). The review points is a measure of the quality of the wine (at least according to one taster's palate). As expected, the price of the wine increases with the quality, although there is considerable variation, and some very expensive wines are rated of relatively low quality, while there are a few exceptional wines at bargain prices.

```{r shiraz, fig.cap="Wine prices and review points for Shiraz and Syrah wines."}
wine_reviews %>%
  filter(variety %in% c("Shiraz", "Syrah")) %>%
  select(points, price) %>%
  ggplot(aes(y=price, x=points)) +
  geom_jitter(height=0, width=0.3, alpha=0.5) +
  scale_y_log10()
```

The jittering in the horizontal direction helps reduce overplotting as `points` is always an integer value. This adds a small amount of random noise to the points variable, but not so much that it overlaps with the neighbouring values. The price is shown on a log scale to allow all the points to be seen more clearly.

Here the most interesting observations are the ones that have an unusual price given their points value. For example, the lowest priced wine above 95 points is a 2007 Syrah from the Rulo vineyard in the Columbia Valley, Washington. It is an anomaly given its high points value and low price, although neither the price nor the points value are particularly unusual.

```{r shiraz2, echo=TRUE}
wine_reviews %>%
  filter(
    variety %in% c("Shiraz", "Syrah"),
    points > 95
  ) %>%
  filter(price == min(price)) %>%
  select(country, state, region, winery, variety, year, points, price)
```

A similar phenomenon occurs whenever you add variables. An anomaly in three dimensions may not appear anomalous in any of the 2-dimensional sets of variables. As the number of dimensions increases, there are more ways for observations to be anomalous, but it is increasingly difficult to find them.

While strip plots and scatterplots are useful for finding anomalies in small- to moderate-sized data sets with one or two dimensions, we will need alternative tools once we have three or more variables, or there is too much data to plot directly.

## Distance and density-based approaches

The tools available for anomaly detection can be roughly divided into two groups: those based on distances and those based on densities. Distance-based tools compute the pairwise distances between observations and identify anomalies as those points which are far from other points. Density-based tools compute the probability density at each observation and identify anomalies as those points with very low density. The two ideas are closely related because density estimates are usually based on distances to other observations, and so often a density estimate at a point is a transformation of the distances between that point and all other observations.

Computing pairwise distances requires $O(n^2)$ calculations where $n$ is the number of observations, so for large data sets, both approaches can be problematic. Therefore there are numerous tricks used to approximate the calculations or speed them up in some way by introducing some assumptions about the distribution of observations, or about the nature of the anomalies.

## Statistical vs machine learning approaches

Anomaly detection has a long history in the statistics literature...

More recently, computer scientists have turned their attention to the problem of anomaly detection, especially as data sets have grown in size and complexity. Anomaly detection arises in cyber security systems (where intrusions are identified as anomalies), in credit-card fraud (where unusual buying patterns are anomalous) and in remote sensing (where unusual changes in land use are anomalies).

Some books and papers distinguish "supervised anomaly detection" from "unsupervised anomaly detection". In the former case, anomalies are identified using human input and then a model or algorithm is employed to learn how to identify new anomalies contained within new data. I do not regard this as anomaly detection and it will not be covered in this book. It is possible, for example, that what a human labels as "anomalous" is not anomalous in a statistical sense. What is called "supervised anomaly detection" is actually a classification problem where the aim is to mimic the human who labelled the training set. In that case, different tools are employed.

In this book, we will only consider unsupervised problems. That is, we have no idea *a priori* what observations are anomalous, and there is no "right" answer.


