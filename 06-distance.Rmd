# Distance-based methods {#ch-distance}


## Pairwise distances and nearest neighbours

Most anomaly detection algorithms are based on pairwise distances between observations. If there are $n$ observations, then there are $n(n-1)/2$ pairwise distances to compute, so this is an $O(n^2)$ operation which can take a very long time for large $n$.

Consequently, some algorithms only compute the pairwise distances of the $k$ nearest observations, although finding those observations requires some additional distances to be computed. For some types of distances, efficient solutions are available using kd trees [@Bentley1975;@Arya1998] that find the $k$ nearest neighbours to each observation in $O(n\log(n))$ time.

Suppose we use the Old Faithful data to find eruptions that are neighbours in the (duration, waiting) space. The `FNN` package uses kd trees to quickly identify the $k$ nearest observations to each eruption.

```{r}
# Find 5 nearest neighbours to each eruption
knn <- oldfaithful %>%
  select(duration, waiting) %>%
  FNN::get.knn(k = 5)
# First eruption in the data set
oldfaithful[1,]
# Five closest observations
oldfaithful[knn$nn.index[1,],]
```

This algorithm is simply computing Euclidean distances between the numeric variables. When the variables have very different scales, the variables with the largest ranges will dominate the distance measures. In this example, durations are much longer than waiting times, and so the duration variable is dominating the calculation of neighbours. Consequently, it is often preferable to scale the data before computing distances.

```{r}
# Find 5 nearest neighbours to each eruption
knn <- oldfaithful %>%
  select(duration, waiting) %>%
  scale() %>%
  FNN::get.knn(k = 5)
# First eruption in the data set
oldfaithful[1,]
# Five closest observations
oldfaithful[knn$nn.index[1,],]
```

The calculation of $k$ nearest neighbours is useful for more than anomaly detection problems. It is also the basis of a popular classification method due to the Berkeley statisticians Evelyn Fix and Joe Hodges [@knn] which is often known as the "kNN algorithm".

For very large data sets, approximations are available which speed up the computation even more, but are less accurate in finding the $k$ nearest neighbours. The `RANN` package uses an approximation that finds the nearest $k$ observations within a specified distance tolerance.

```{r}
# Find 5 approximate nearest neighbours to each eruption
kann <- oldfaithful %>%
  select(duration, waiting) %>%
  scale() %>%
  RANN::nn2(k = 6, eps = 2)
# First eruption in the data set
oldfaithful[1,]
# Five closest observations
oldfaithful[kann$nn.idx[1,],]
```

This function also returns the original observation, so `k=6` has been set instead. Here the fourth closest observation has been omitted, and another nearby observation has been included instead, but otherwise the approximation has identified four of the five nearest observations.

## Local outlier factors

A popular way of using $k$-nearest neighbours for anomaly detection is via local outlier factors [@lof]. This is similar to the idea discussed in \@ref(sec-kdescores) of finding points with low probability density estimates, in that it is designed to find points in areas with few surrounding observations.

Suppose we write the distance between observations $\bm{y}_i$ and $\bm{y}_j$ as $\|\bm{y}_i - \bm{y}_j\|$, and let $d_{i,k}$ be the distance between observation $\bm{y}_i$ and its $k$th nearest neighbour.

Let $N_{i,k}$ be the set of $k$ nearest neighbours within $d_{i,k}$ of $\bm{y}_i$. (If there are multiple observations all exactly $d_{i,k}$ from $\bm{y}_i$, then $N_{i,k}$ may contain more than $k$ observations, but we will ignore that issue here.)

Note that an observation $\bm{y}_j$ may be within $N_{i,k}$ while $\bm{y}_i$ does not fall within $N_{j,k}$, as shown in the diagram below.

```{r njk, fig.cap="A synthetic data set of 11 observations. Nearest neighbourhoods containing five observations each are shown for $\\bm{y}_1$ (in orange) and $\\bm{y}_2$ (in blue). The neighbourhood of $\\bm{y}_1$ contains $\\bm{y}_2$ in its nearest five observations, but $\\bm{y}_2$ does not include $\\bm{y}_1$ in its nearest five observations.", echo=FALSE, warning=FALSE}
set.seed(2)
cols <- c("#D55E00", "#0072B2")
df <- tibble(
    x = c(rnorm(5), rnorm(6, 5, 1)),
    y = c(rnorm(5), rnorm(6, 5, 1))
  )
chosen <- c(3,11)
knn <- dbscan::kNN(df, 5)$id[chosen,]
df <- df %>%
  mutate(
    d = dbscan::kNNdist(df,5),
    n15 = if_else(row_number() %in% knn[1,], "N15", "NO"),
    n25 = if_else(row_number() %in% knn[2,], "N25", "NO")
  )
df %>%
  ggplot() +
  ggforce::geom_circle(aes(x0=x,y0=y,r=d, col=c("N15","N25"), fill=c("N15","N25")),
                       alpha=0.2, data=df[chosen,]) +
  geom_point(aes(x=x, y=y), size=3) +
  #geom_point(aes(x=x, y=y), size=3, data=df[chosen,], col=cols) +
  annotate("text", x=df$x[chosen]+0.3, y=df$y[chosen]+0.3,
           label=latex2exp::TeX(paste0("$y_",1:2,"$"), bold=TRUE), col=cols) +
  annotate("text", x=c(-0.5,3.6), y=c(4.2,6),
           label=latex2exp::TeX(paste0("$N_{",1:2,",5}$")), col=cols) +
  geom_segment(aes(x=x, y=y,xend=c(7.75,8.75), yend=y),
               arrow = arrow(length = unit(0.02, "npc")),
               data=df[chosen,], col=cols) +
  annotate("text", x=c(4.7,7), y=c(-0.8,4.1),
           label=latex2exp::TeX(paste0("$d_{",1:2,",5}$")), col=cols) +
  coord_fixed(xlim=c(-4,8.5), ylim=range(df$y)) +
  guides(col="none",fill="none") +
  theme_void()
```

Let $r_k(i,j) = \max(d_{j,k}, \|\bm{y}_i-\bm{y}_j\|)$ be the "reachability" of $\bm{y}_i$ from $\bm{y}_j$. Thus, $r_k(i,j)$ is the distance between observations $\bm{y}_i$ and $\bm{y}_j$ when they are far from each other, but is equal to $d_{j,k}$ if $\bm{y}_i$ is one of the $k$ nearest neighbours of $\bm{y}_j$. The reachability is a truncated variant of the usual Euclidean distance $\|\bm{y}_i-\bm{y}_j\|$ so that it is not less than $d_{j,k}$.

The average reachability of $\bm{y}_i$ *from* its nearest neighbours is given by
$$
  \bar{r}_{i,k} = k^{-1} \sum_{\bm{y}_j \in N_{i,k}} r_k(i,j)
$$
This is not the same as the average reachability of the neighbours *from* $\bm{y}_i$ which, by definition, would be $d_{i,k}$. An observation will have high average reachability if it is far from its neighbours, whereas it will have low average reachability if it has many close neighbours.

Then the local outlier factor for observation $\bm{y}_i$ is given by
$$
\ell_{i,k} = \frac{\bar{r}_{i,k}}{k}\sum_{\bm{y}_j \in N_{i,k}} \bar{r}^{-1}_{j,k}.
$$
Thus, it is the ratio between $\bar{r}_{i,k}$ and the average value of $\bar{r}^{-1}_{j,k}$ for points within its neighbourhood.

This provides a relative measure of the density of each observation compared to its neighbours. An observation is regarded as an anomaly if it is in a low-density region (far from its neighbours) while its neighbours are in higher density regions (with many neighbours nearby). A value of $\ell_{i,k}$ much greater than 1 shows that the observation has much larger average reachability compared to its neighbours, and so is regarded as an anomaly.

One problem with this definition is that $\ell_{i,k}$ can be infinite. If the data set contains at least $k+1$ identical observations, then the average reachability $\bar{r}_k(j,k)$ will be 0 if $\bm{y}_j$ is one of the group of identical observations. Consequently, $\ell_{i,k} = \infty$ if $\bm{y}_i$ is a neighbour to one of the group of identical observations.  In this book we use a slightly different definition from that used elsewhere and replace these infinite values with zeros.

Another problem is that it can be difficult to determine an appropriate value for $k$.

### Example: Old Faithful data

```{r}
of_scores <- oldfaithful %>%
  mutate(lof = lof_scores(duration, k=150))
of_scores %>% arrange(desc(lof))
of_scores %>%
  filter(duration < 7000) %>%
  ggplot(aes(x = duration, y = lof)) +
  geom_point()
```

Again, the two large scores correspond to the extreme 2 hour duration and the tiny 1 second duration. The value of $k=150$ has been chosen by trial and error.

